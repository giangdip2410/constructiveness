{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A6cf1WTfEGFs"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mOIC3gguESlA"
   },
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ls6z_U-6KDJu"
   },
   "outputs": [],
   "source": [
    "RETRAIN_MODEL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jrzBsKLQSb7t"
   },
   "outputs": [],
   "source": [
    "# Hparams\n",
    "\n",
    "TRAINABLE_LAYERS = 6\n",
    "FC_LAYERS = [256, 128, 64]\n",
    "DROPOUT_RATE = 0.5\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zg_-yZZlyPE7"
   },
   "outputs": [],
   "source": [
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "\n",
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_PATH = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "# We'll set sequences to be at most 256 tokens long.\n",
    "max_seq_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K87DT5TlEb83"
   },
   "outputs": [],
   "source": [
    "# TODO(varada): Please change the paths in this cell to the appropriate local path\n",
    "TRAIN_DATA = os.environ['C3_TRAIN'] # 'C3_train.csv'\n",
    "TEST_DATA = os.environ['C3_TEST'] # 'C3_test.csv'\n",
    "NYT_DATA = pd.read_csv(os.environ['NYT_YNACC'])# 'NYT_YNACC_feats_preprocessed.csv'\n",
    "SOCC_DATA = pd.read_csv(os.environ['SOCC_ANNOTATED_FEATS_PREPROCESSED'])# 'SOCC_constructiveness_annotations_feats_preprocessed.csv'\n",
    "MODEL_OUTPUT_DIR = os.environ['HOME'] + '/models'# 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLS_hnAKF4uJ"
   },
   "outputs": [],
   "source": [
    "def df_from_path(path):\n",
    "  df = pd.read_csv(tf.gfile.Open(path, 'r'))\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t6VBl1DwhHu5"
   },
   "outputs": [],
   "source": [
    "train = df_from_path(TRAIN_DATA)\n",
    "test = df_from_path(TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KP7pQIFAHily"
   },
   "outputs": [],
   "source": [
    "DATA_COLUMN = 'comment_text'\n",
    "LABEL_COLUMN = 'constructive_binary'\n",
    "label_list = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "67yHSZT1Ifsj"
   },
   "outputs": [],
   "source": [
    "rain_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rZgh_zmJIjOl"
   },
   "outputs": [],
   "source": [
    "def create_tokenizer_from_hub_module(model_path):\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(model_path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return bert.tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module(BERT_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eH4KXsiuImyw"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Convert our train and test features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, max_seq_length, tokenizer)\n",
    "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, max_seq_length, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNas9qSeIq0-"
   },
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, n_fine_tune_layers, **kwargs):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            BERT_MODEL_PATH,\n",
    "            trainable=self.trainable,\n",
    "            name=\"{}_module\".format(self.name)\n",
    "        )\n",
    "\n",
    "        trainable_vars = self.bert.variables\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "\n",
    "        print(trainable_vars)\n",
    "        print(len(trainable_vars))\n",
    "        # Select how many layers to fine tune\n",
    "        if self.n_fine_tune_layers is not None:\n",
    "          if self.n_fine_tune_layers > 0:\n",
    "            trainable_vars = trainable_vars[-self.n_fine_tune_layers :]\n",
    "          elif self.n_fine_tune_layers == 0:\n",
    "            trainable_vars = []\n",
    "          else:\n",
    "            raise ValueError('n_fine_tune_layers must be >= 0 or None.')\n",
    "\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "            \n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "            \"pooled_output\"\n",
    "        ]\n",
    "        return result\n",
    "\n",
    "    def get_config(self):\n",
    "      config = super().get_config()\n",
    "      config['n_fine_tune_layers'] = self.n_fine_tune_layers\n",
    "      return config\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74GGMv30JGjb"
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model(max_seq_length): \n",
    "    in_id = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    dense = BertLayer(n_fine_tune_layers=TRAINABLE_LAYERS)(bert_inputs)\n",
    "    for layers in FC_LAYERS:\n",
    "      dense = tf.keras.layers.Dense(layers, activation='relu')(dense)\n",
    "      dense = tf.keras.layers.Dropout(DROPOUT_RATE)(dense)\n",
    "    pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N41NH2dpzOmN"
   },
   "outputs": [],
   "source": [
    "def get_features(features):\n",
    "  input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "  for f in features:\n",
    "    input_ids.append(f.input_ids)\n",
    "    input_masks.append(f.input_mask)\n",
    "    segment_ids.append(f.segment_ids)\n",
    "    labels.append(f.label_id)\n",
    "  return (\n",
    "    np.array(input_ids),\n",
    "    np.array(input_masks),\n",
    "    np.array(segment_ids),\n",
    "    np.array(labels).reshape(-1, 1),\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KWFtjwIWJIWc"
   },
   "outputs": [],
   "source": [
    "train_input_ids, train_input_masks, train_segment_ids, train_labels = get_features(train_features)\n",
    "test_input_ids, test_input_masks, test_segment_ids, test_labels = get_features(test_features)\n",
    "\n",
    "model = build_model(max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OPlwojaR1US2"
   },
   "outputs": [],
   "source": [
    "# Instantiate variables\n",
    "initialize_vars(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z9XdWQ6gLwUo"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if RETRAIN_MODEL:\n",
    "  model.fit(\n",
    "      [train_input_ids, train_input_masks, train_segment_ids], \n",
    "      train_labels,\n",
    "      validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n",
    "      epochs=EPOCHS,\n",
    "      batch_size=32\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GNeqzFbiJJ9e"
   },
   "outputs": [],
   "source": [
    "model_filename = 'BertModel_B%s_F%s_D%s_E%s.h5' % (TRAINABLE_LAYERS, len(FC_LAYERS), DROPOUT_RATE, EPOCHS)\n",
    "if RETRAIN_MODEL:\n",
    "  model.save_weights(os.path.join(MODEL_OUTPUT_DIR, model_filename))\n",
    "else:\n",
    "  model.load_weights(os.path.join(MODEL_OUTPUT_DIR, model_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aJPBU7cXQCIn"
   },
   "source": [
    "### Eval on Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GJuqST51Zblg"
   },
   "outputs": [],
   "source": [
    "def predictions_from_df(bert_model, df, data_col, label_col):\n",
    "  test_InputExamples = df.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[data_col], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[label_col]), axis = 1)\n",
    "  test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, max_seq_length, tokenizer)\n",
    "  test_input_ids, test_input_masks, test_segment_ids, test_labels = get_features(test_features)\n",
    "  predictions = bert_model.predict([test_input_ids, \n",
    "                                test_input_masks, \n",
    "                                test_segment_ids]\n",
    "                              )\n",
    "  labels = df[label_col]\n",
    "  return predictions, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z3gvy8hjRS5E"
   },
   "outputs": [],
   "source": [
    "def metrics_from_df(bert_model, df, data_col = DATA_COLUMN, label_col = LABEL_COLUMN):\n",
    "  predictions, labels = predictions_from_df(bert_model, df, data_col, label_col)\n",
    "  auc = roc_auc_score(labels, predictions)\n",
    "  f1 = f1_score(labels, np.round(predictions))\n",
    "  return auc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tRmI3GfrIy9L"
   },
   "outputs": [],
   "source": [
    "c3_test = df_from_path(TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "37qSM6UWR-4t"
   },
   "outputs": [],
   "source": [
    "metrics_from_df(model, c3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iFRp_P9kJ8FD"
   },
   "outputs": [],
   "source": [
    "nyt_test = df_from_path(NYT_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uFtjhwNTh6qo"
   },
   "outputs": [],
   "source": [
    "nyt_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V3CdED7jewj4"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if RETRAIN_MODEL:\n",
    "  metrics_from_df(model, nyt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fObYEBhWe-zv"
   },
   "outputs": [],
   "source": [
    "socc_test = df_from_path(SOCC_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ppz2-tPSiMit"
   },
   "outputs": [],
   "source": [
    "socc_test['constructive_binary'] = np.round(socc_test['constructive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aqVWeXtKh-3Y"
   },
   "outputs": [],
   "source": [
    "socc_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MbyHkvd0iANG"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "metrics_from_df(model, socc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ms-nXXC8jBhc"
   },
   "source": [
    "### Save Predictions for Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c0TaRkXGjE_u"
   },
   "outputs": [],
   "source": [
    "predictions, labels = predictions_from_df(model, c3_test, DATA_COLUMN, LABEL_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xz9VnHG_jcJT"
   },
   "outputs": [],
   "source": [
    "output_df = c3_test[['comment_text', 'constructive_binary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-u4QkUY8kAYo"
   },
   "outputs": [],
   "source": [
    "output_df['comment_len'] = output_df.comment_text.apply(lambda x: len(x.strip().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ElzoXCDkOzj"
   },
   "outputs": [],
   "source": [
    "# Sanity Check\n",
    "assert all(output_df['constructive_binary'] == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8g0b_Wykf5A"
   },
   "outputs": [],
   "source": [
    "output_df['prediction proba'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L2PlzfqTkrB4"
   },
   "outputs": [],
   "source": [
    "output_df['prediction'] = np.round(predictions)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Keras BERT Model (local).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
